rm(list = ls())
training_full <- read.csv("train.csv", header = TRUE)
validation_size <- floor(0.8*nrow(training_full))
picked <- sample(seq_len(nrow(training_full)), size = validation_size)
train <- training_full[picked,]
validation <- training_full[-picked,]
test <- read.csv("test.csv", header = TRUE)
samples <- read.csv("sample_submission.csv", header = TRUE)
threshold <- 0.05
problemsTr <- c(colMeans(is.na(train)) > threshold)
problemsTe <- c(colMeans(is.na(train)) > threshold)
problemsV <- c(colMeans(is.na(train)) > threshold)
holder <- c(0)
count <- 1
while (count < length(train)){
if (problemsTr[[count]] | problemsTe[[count]] | problemsV[[count]]){
holder <- append(holder,count)
}
count <- count + 1
}
train <- na.omit(train[,-holder])
test <- na.omit(test[,-holder])
validation <- na.omit(validation[,-holder])
anyNA(train)
anyNA(test)
anyNA(validation)
null <- lm(SalePrice ~ 1, data = train)
full <- lm(SalePrice ~ ., data = train)
forward <- stepAIC(null, scope = list(lower = null, upper = full), direction = 'forward', k = log(length(train$SalePrice)))
View(forward)
pred <- predict(forward,validation)
pred <- predict(forward,validation, na.action = na.exclude)
null <- lm(SalePrice ~ 1, data = train)
full <- lm(SalePrice ~ ., data = train, na.action = na.exclude)
forward <- stepAIC(null, scope = list(lower = null, upper = full), direction = 'forward', k = log(length(train$SalePrice)))
pred <- predict(forward,validation, na.action = na.exclude)
View(train)
View(validation)
library(MASS)
rm(list = ls())
training_full <- read.csv("train.csv", header = TRUE)
validation_size <- floor(0.8*nrow(training_full))
picked <- sample(seq_len(nrow(training_full)), size = validation_size)
train <- training_full[picked,]
validation <- training_full[-picked,]
test <- read.csv("test.csv", header = TRUE)
samples <- read.csv("sample_submission.csv", header = TRUE)
threshold <- 0.05
problemsTr <- c(colMeans(is.na(train)) > threshold)
problemsTe <- c(colMeans(is.na(train)) > threshold)
problemsV <- c(colMeans(is.na(train)) > threshold)
holder <- c(0)
count <- 1
while (count < length(train)){
if (problemsTr[[count]] | problemsTe[[count]] | problemsV[[count]]){
holder <- append(holder,count)
}
count <- count + 1
}
train <- na.omit(train[,-holder])
test <- na.omit(test[,-holder])
validation <- na.omit(validation[,-holder])
null <- lm(SalePrice ~ 1, data = train)
full <- lm(SalePrice ~ ., data = train, na.action = na.exclude)
forward <- stepAIC(null, scope = list(lower = null, upper = full), direction = 'forward', k = log(length(train$SalePrice)))
pred <- predict(forward,validation, na.action = na.exclude)
library(MASS)
rm(list = ls())
training_full <- read.csv("train.csv", header = TRUE)
validation_size <- floor(0.8*nrow(training_full))
picked <- sample(seq_len(nrow(training_full)), size = validation_size)
train <- training_full[picked,]
validation <- training_full[-picked,]
test <- read.csv("test.csv", header = TRUE)
samples <- read.csv("sample_submission.csv", header = TRUE)
threshold <- 0.05
problemsTr <- c(colMeans(is.na(train)) > threshold)
problemsTe <- c(colMeans(is.na(test)) > threshold)
problemsV <- c(colMeans(is.na(validation)) > threshold)
holder <- c(0)
count <- 1
while (count < length(train)){
if (problemsTr[[count]] | problemsTe[[count]] | problemsV[[count]]){
holder <- append(holder,count)
}
count <- count + 1
}
train <- na.omit(train[,-holder])
test <- na.omit(test[,-holder])
validation <- na.omit(validation[,-holder])
null <- lm(SalePrice ~ 1, data = train)
full <- lm(SalePrice ~ ., data = train, na.action = na.exclude)
forward <- stepAIC(null, scope = list(lower = null, upper = full), direction = 'forward', k = log(length(train$SalePrice)))
pred <- predict(forward,validation, na.action = na.exclude)
library(MASS)
rm(list = ls())
training_full <- read.csv("train.csv", header = TRUE)
validation_size <- floor(0.8*nrow(training_full))
picked <- sample(seq_len(nrow(training_full)), size = validation_size)
train <- training_full[picked,]
validation <- training_full[-picked,]
test <- read.csv("test.csv", header = TRUE)
samples <- read.csv("sample_submission.csv", header = TRUE)
threshold <- 0.05
problemsTrF <- c(colMeans(is.na(training_full)) > threshold)
problemsTr <- c(colMeans(is.na(train)) > threshold)
problemsTe <- c(colMeans(is.na(test)) > threshold)
problemsV <- c(colMeans(is.na(validation)) > threshold)
holder <- c(0)
count <- 1
while (count < length(train)){
if (problemsTr[[count]] | problemsTe[[count]] | problemsV[[count]]){
holder <- append(holder,count)
}
count <- count + 1
}
train <- na.omit(train[,-holder])
test <- test[,-holder]
validation <- na.omit(validation[,-holder])
training_full <- na.omit(training_full[,-holder])
null <- lm(SalePrice ~ 1, data = training_full)
full <- lm(SalePrice ~ ., data = training_full)
forward <- stepAIC(null, scope = list(lower = null, upper = full), direction = 'forward', k = log(length(train$SalePrice)))
forward <- stepAIC(null, scope = list(lower = null, upper = full), direction = 'forward', k = log(length(training_full$SalePrice)))
pred <- predict(forward,test, na.action = na.exclude)
pred <- predict(forward,train, na.action = na.exclude)
library(Metrics)
install.packages("https://www.rdocumentation.org/packages/Metrics")
package install.packages(https://www.rdocumentation.org/packages/Metrics)
install.packages(https://www.rdocumentation.org/packages/Metrics)
install.packages(https://www.rdocumentation.org/packages/Metrics)
install.packages(https:/www.rdocumentation.org/packages/Metrics)
install.packages(https://www.rdocumentation.org/packages/Metrics)
install.packages("Metrics")
library(Metrics)
library(Metrics)
pred <- predict(forward,train, na.action = na.exclude)
library(Metrics)
pred <- predict(forward,train, na.action = na.exclude)
result <- rmse(training_full$SalePrice,pred)
print(result)
library(Metrics)
pred <- predict(forward,train, na.action = na.exclude)
result <- rmse(log(training_full$SalePrice),log(pred))
print(result)
library(MASS)
rm(list = ls())
training_full <- read.csv("train.csv", header = TRUE)
validation_size <- floor(0.8*nrow(training_full))
picked <- sample(seq_len(nrow(training_full)), size = validation_size)
train <- training_full[picked,]
validation <- training_full[-picked,]
test <- read.csv("test.csv", header = TRUE)
samples <- read.csv("sample_submission.csv", header = TRUE)
threshold <- 0.05
problemsTrF <- c(colMeans(is.na(training_full)) > threshold)
problemsTr <- c(colMeans(is.na(train)) > threshold)
problemsTe <- c(colMeans(is.na(test)) > threshold)
problemsV <- c(colMeans(is.na(validation)) > threshold)
holder <- c(0)
count <- 1
while (count < length(train)){
if (problemsTr[[count]] | problemsTe[[count]] | problemsV[[count]]){
holder <- append(holder,count)
}
count <- count + 1
}
train <- na.omit(train[,-holder])
test <- test[,-holder]
validation <- na.omit(validation[,-holder])
training_full <- na.omit(training_full[,-holder])
null <- lm(SalePrice ~ 1, data = training_full)
full <- lm(SalePrice ~ ., data = training_full)
forwardBIC <- stepAIC(null, scope = list(lower = null, upper = full), direction = 'forward', k = log(length(training_full$SalePrice)))
forwardAIC <- stepAIC(null, scope = list(lower = null, upper = full), direction = 'forward', k = 2)
backwardBIC <- stepAIC(null, scope = list(lower = null, upper = full), direction = 'backward', k = log(length(training_full$SalePrice)))
backwardAIC <- stepAIC(null, scope = list(lower = null, upper = full), direction = 'backward', k = 2)
library(Metrics)
predFB <- predict(forwardBIC,training_full, na.action = na.exclude)
predFA <- predict(forwardAIC,training_full, na.action = na.exclude)
predBB <- predict(backwardBIC,training_full, na.action = na.exclude)
predBA <- predict(backwardAIC,training_full, na.action = na.exclude)
resultFB <- rmse(log(training_full$SalePrice),log(predFB))
resultFA <- rmse(log(training_full$SalePrice),log(predFA))
resultBB <- rmse(log(training_full$SalePrice),log(predBB))
resultBA <- rmse(log(training_full$SalePrice),log(predBA))
print("Result Forward BIC: ")
print(resultFB)
print(" ---------------------")
print("Result Forward AIC: ")
print(resultFA)
print(" ---------------------")
print("Result Backward BIC: ")
print(resultBB)
print(" ---------------------")
print("Result Backward AIC: ")
print(resultBA)
length(test[[1]])
predictionsBIC <- predict(forwardBIC,test)
predictionsAIC <- predict(backwardAIC,test)
View(test)
View(samples)
answer2 <- merge(test[[Id]],predictionsAIC)
answer2 <- merge(test[[1]],predictionsAIC)
View(answer2)
?merge
answer1 <- data.frame(test[[1]],predictionsBIC)
answer2 <- data.frame(test[[1]],predictionsAIC)
View(answer1)
write.csv(answer1,"/users/willgraham/desktop/Machine Learning")
write.csv(answer1,"Solutions")
View(answer1)
write.csv(answer1,"Solutions.csv")
birth_data <- read.delim("births.txt")
birth_data <- read.delim("~/desktop/Edinburgh Downloads/births.txt")
plot(birth_data)
View(birth_data)
plot(birth_data)
View(birth_data)
x <- birth_data$Hour_ending_at
y <- birth_data$Number_of_births
mdl <- lm(y ~ x)
abline(mdl)
summary(mdl)
``` {r}
WG Initializiation
``` {r}
setwd("~/Desktop/Statistical-Programming-2022")
a <- scan("/Users/willgraham/Desktop/Edinburgh Downloads/pg10.txt",what="character",skip=104) ## skip contents
n <- length(a)
a <- a[-((n-2886):n)] ## strip license
a <- a[-grep("[0123456789]:[0123456789]",a)] ## strip out verse numbers
```
setwd("~/Desktop/Statistical-Programming-2022")
a <- scan("/Users/willgraham/Desktop/Edinburgh Downloads/pg10.txt",what="character",skip=104) ## skip contents
n <- length(a)
a <- a[-((n-2886):n)] ## strip license
a <- a[-grep("[0123456789]:[0123456789]",a)] ## strip out verse numbers
length(a)
a[[0]]
a[0]
a[1]
unique(a)
knitr::opts_chunk$set(echo = TRUE)
```{r}
a <- scan("pg10.txt",what="character",skip=104) ## skip contents
n <- length(a)
a <- a[-((n-2886):n)] ## strip license
a <- a[-grep("[0123456789]:[0123456789]",a)] ## strip out verse numbers
split_punct <- function(string){
## Separating words with punctuation marks
indexes <- grep("[^a-z ^A-Z]",a) ## obtain the indexes of words containing non-letter characters
## ...
}
punct_indexes <- split_punct(a)
a[punct_indexes][0]
a[punct_indexes][1]
a[punct_indexes][2]
a[punct_indexes][1:100]
?grep
?substring
split_punct <- function(string){
## Separating words with punctuation marks
indexes <- grep("[^a-z ^A-Z]",a) ## obtain the indexes of words containing non-letter characters
apos <- grep("'",a)
return(apos)
## ...
}
punct_indexes <- split_punct(a)
punct_indexes
split_punct <- function(string){
## Separating words with punctuation marks
indexes <- grep("[^a-z ^A-Z]",a) ## obtain the indexes of words containing non-letter characters
apos <- grep("wife",a)
return(apos)
## ...
}
punct_indexes <- split_punct(a)
punct_indexes
a[punct_indexes]
knitr::opts_chunk$set(echo = TRUE)
```{r}
a <- scan("pg10.txt",what="character",skip=104) ## skip contents
n <- length(a)
a <- a[-((n-2886):n)] ## strip license
a <- a[-grep("[0123456789]:[0123456789]",a)] ## strip out verse numbers
split_punct <- function(string){
## Separating words with punctuation marks
indexes <- grep("[^a-z ^A-Z]",a) ## obtain the indexes of words containing non-letter characters
## ...
}
split_punct <- function(string){
## Separating words with punctuation marks
indexes <- grep("[^a-z ^A-Z]",a) ## obtain the indexes of words containing non-letter characters
return(indexes)
## ...
}
punct_indexes <- split_punct(a)
a[punct_indexes]
words <- a[punct_indexes]
length(words)
words2 <- [0]*length(words)
punct_indexes
punct_indexes <- split_punct(a)
words <- a[punct_indexes]
new_a <- c(1:(length(a) + length(words)))
length(new_a)
a[1:100]
test <- 'test'
test[1:-1]
test[-1]
test[5]
test[4]
substr('test', 1, length('test'))
length('test')
substr('test', 1, nchar('test'))
substr('test', 1, nchar('test')-1)
substr('test', nchar('test'), nchar('test'))
a <- a[1:100]
for (i in c(1:length(a))) {
if (a[i] %in% punct) {
new_a[i+tracker] <- substr(a[i], 1, nchar(a[i]) - 1)
new_a[i + tracker + 1] <- substr(a[i], nchar(a[i]), nchar(a[i]))
tracker <- tracker + 1
} else {new_a[i + tracker] <- a[i]}
}
n <- length(a)
a <- scan("pg10.txt",what="character",skip=104) ## skip contents
a <- scan("pg10.txt",what="character",skip=104) ## skip contents
n <- length(a)
a <- a[-grep("[0123456789]:[0123456789]",a)] ## strip out verse numbers
split_punct <- function(string){
## Separating words with punctuation marks
indexes <- grep("[^a-z ^A-Z]",a) ## obtain the indexes of words containing non-letter characters
return(indexes)
## ...
}
punct_indexes <- split_punct(a)
punct <- a[punct_indexes]
new_a <- c(1:(length(a) + length(punct)))
tracker <- 0
a <- a[1:100]
for (i in c(1:length(a))) {
if (a[i] %in% punct) {
new_a[i+tracker] <- substr(a[i], 1, nchar(a[i]) - 1)
new_a[i + tracker + 1] <- substr(a[i], nchar(a[i]), nchar(a[i]))
tracker <- tracker + 1
} else {new_a[i + tracker] <- a[i]}
}
new_a[1:100]
a <- scan("pg10.txt",what="character",skip=104) ## skip contents
n <- length(a)
a <- a[-((n-2886):n)] ## strip license
a <- a[-grep("[0123456789]:[0123456789]",a)] ## strip out verse numbers
a[1:100]
?match
?match
?tabulate
tabulate(c(2,3,5))
knitr::opts_chunk$set(echo = TRUE)
a <- scan("pg10.txt",what="character",skip=104) ## skip contents
n <- length(a)
a <- a[-((n-2886):n)] ## strip license
a <- a[-grep("[0123456789]:[0123456789]",a)] ## strip out verse numbers
indexes_split_punct <- function(string){
## Separating words with punctuation marks
indexes <- grep("[^a-z ^A-Z]",a) ## obtain the indexes of words containing non-letter characters
return(indexes)
}
split_punct <- function(b, test){
punct_indexes <- indexes_split_punct(b)
punct <- b[punct_indexes]
new_b <- c(1:(length(b) + length(punct)))
tracker <- 0
if (test == TRUE){
b <- b[1:100]
new_b <- new_b[1:115]
}
for (i in c(1:length(b))) {
if (b[i] %in% punct) {
new_b[i+tracker] <- substr(b[i], 1, nchar(b[i]) - 1)
new_b[i + tracker + 1] <- substr(b[i], nchar(b[i]), nchar(b[i]))
tracker <- tracker + 1
} else {new_b[i + tracker] <- b[i]}
}
return(new_b)
}
#Lowering capitals
new_b <- split_punct(a,TRUE)
#Lowering capitals
new_b <- split_punct(a,TRUE)
lower_new_b <- tolower(new_b)
lower_new_b <- tolower(new_b)
unique_words <- unique(lower_new_b)
index_match <- match(lower_new_b,unique_words)
tabulate_index_match <- tabulate(index_match)
sort_results <- sort(tabulate_index_match, index.return = TRUE, decreasing = TRUE)
#Lowering capitals
new_b[new_b == 'darkness']
#Lowering capitals
length(new_b[new_b == 'darkness'])
?cbind
a <- scan("pg10.txt",what="character",skip=104) ## skip contents
n <- length(a)
a <- a[-((n-2886):n)] ## strip license
a <- a[-grep("[0123456789]:[0123456789]",a)] ## strip out verse numbers
indexes_split_punct <- function(string){
## Separating words with punctuation marks
indexes <- grep("[^a-z ^A-Z]",a) ## obtain the indexes of words containing non-letter characters
return(indexes)
}
split_punct <- function(b, test){
punct_indexes <- indexes_split_punct(b)
punct <- b[punct_indexes]
new_b <- c(1:(length(b) + length(punct)))
tracker <- 0
if (test == TRUE){
b <- b[1:100]
new_b <- new_b[1:115]
}
for (i in c(1:length(b))) {
if (b[i] %in% punct) {
new_b[i+tracker] <- substr(b[i], 1, nchar(b[i]) - 1)
new_b[i + tracker + 1] <- substr(b[i], nchar(b[i]), nchar(b[i]))
tracker <- tracker + 1
} else {new_b[i + tracker] <- b[i]}
}
return(new_b)
}
#Lowering capitals
new_b <- split_punct(a, TRUE)
lower_new_b <- tolower(new_b)
unique_words <- unique(lower_new_b)
index_match <- match(lower_new_b, unique_words)
tabulate_index_match <- tabulate(index_match)
sort_results <- sort(tabulate_index_match, index.return = TRUE, decreasing = TRUE)
top_500 <- sort_results$ix[1 : 10]
result_list <- unique_words[top_500]
T_array <- T_array[rowSums(T_array) |> is.na() == FALSE]
common_word_match <- match(lower_new_b, result_list)
first_column <- common_word_match[1 : (length(common_word_match) - 2)]
second_column <- first_column[2 : (length(common_word_match) - 1)]
third_column <- first_column[3 : length(common_word_match)]
T_array <- cbind(first_column, second_column, third_column)
T_array <- T_array[is.na(rowSums(T_array)) == FALSE]
T_array
T_array <- T_array[T_array[is.na(rowSums(T_array)) == FALSE]]
common_word_match <- match(lower_new_b, result_list)
first_column <- common_word_match[1 : (length(common_word_match) - 2)]
second_column <- first_column[2 : (length(common_word_match) - 1)]
third_column <- first_column[3 : length(common_word_match)]
T_array <- cbind(first_column, second_column, third_column)
T_array <- T_array[T_array[is.na(rowSums(T_array)) == FALSE]]
T_array
T_array <- T_array[is.na(rowSums(T_array)) == FALSE]
common_word_match <- match(lower_new_b, result_list)
first_column <- common_word_match[1 : (length(common_word_match) - 2)]
second_column <- first_column[2 : (length(common_word_match) - 1)]
third_column <- first_column[3 : length(common_word_match)]
T_array <- cbind(first_column, second_column, third_column)
T_array <- T_array[is.na(rowSums(T_array)) == FALSE]
print(T_array)
first_column <- common_word_match[1 : (length(common_word_match) - 2)]
second_column <- first_column[2 : (length(common_word_match) - 1)]
third_column <- first_column[3 : length(common_word_match)]
T_array <- cbind(first_column, second_column, third_column)
print(T_array)
test <- T_array[is.na(rowSums(T_array)) == FALSE]
test
test <- is.na(rowSums(T_array)
test <- is.na(rowSums(T_array))
test <- is.na(rowSums(T_array))
test
T_array <- cbind(T_array, test)
print(T_array)
test_array <- T_array[T_array[4] == 0]
print(T_array)
common_word_match <- match(lower_new_b, result_list)
common_word_match <- match(lower_new_b, result_list)
first_column <- common_word_match[1 : (length(common_word_match) - 2)]
second_column <- first_column[2 : (length(common_word_match) - 1)]
third_column <- first_column[3 : length(common_word_match)]
T_array <- cbind(first_column, second_column, third_column)
test <- is.na(rowSums(T_array))
T_array <- cbind(T_array, test)
test_array <- T_array[,T_array[4] == 0]
test_array
is.na(rowSums(T_array))
z <- T_array <- T_array[is.na(rowSums(T_array)) == FALSE]
z
T_array
common_word_match <- match(lower_new_b, result_list)
first_column <- common_word_match[1 : (length(common_word_match) - 2)]
second_column <- first_column[2 : (length(common_word_match) - 1)]
third_column <- first_column[3 : length(common_word_match)]
T_array <- cbind(first_column, second_column, third_column)
z <- T_array[is.na(rowSums(T_array)) == FALSE]
is.na(rowSums(T_array))
T_array
z
length(T_array)
?cbind
common_word_match <- match(lower_new_b, result_list)
first_column <- common_word_match[1 : (length(common_word_match) - 2)]
second_column <- first_column[2 : (length(common_word_match) - 1)]
third_column <- first_column[3 : length(common_word_match)]
T_array <- data.frame(first_column, second_column, third_column)
T_array
z <- T_array[is.na(rowSums(T_array)) == FALSE]
z <- T_array[,is.na(rowSums(T_array)) == FALSE]
z <- T_array[is.na(rowSums(T_array)) == FALSE,]
z
