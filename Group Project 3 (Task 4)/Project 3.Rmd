---
title: "Project 1"
author: "Will Graham; Richelle Lee; Robin Lin"
date: '2022-10-06'
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
newt <- function(theta, func, grad, hess = NULL, ..., tol, fscale, maxit, max.half, eps){
  # initialise random value of theta
  # Check objective and derivatives are finite
  
  # Check maxit
  # Save the value of D at theta (alpha)
  # Calculate minimum of approximation function at theta
    ## Calculate the gradient and hessian matrix of the obj func
    ## Check if the gradient converged
      ### If yes:
        #### If hessian is not positive definite, give a warning, and retrun values
        #### If hessian is postive definite, return values
    ## Calculate eigen decomp on the hessian
      ### Check lambdas for positivity, if not, perturb hessian matrix and recalculate eigen decomp
    ## Get inverse of hessian by taking reciprocal of lambda
    ## Return theta that minimises the approximation funct
  
  # Set stepsize = theta hat - theta
  # Compare value of D at theta hat (beta) to alpha:
    ## Case 1: alpha less than beta
      ### try dividing stepsize by 2 until valid obj funct at theta:
      ### set theta hat = theta + stepsize*0.5
  # rerun this loop
  # if runs max.half number of times without improving, stop
  
  
  
}

```

